{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from math import sqrt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We set a fixed seed for repeatability\n",
    "random_seed = 12345  # This seed is also used in the pandas sample() method below\n",
    "torch.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your first task as a Data Scientist\n",
    "You just started in your new job as Data Scientist at Awesome Corp. One of the customers recently had a temporary sensor failure causing the loss of very valuable flow rate data. They need an accurate estimate of the missing flow rates ASAP so that they can optimize their system. Naturally, you are given the job since you have mastered deep learning.\n",
    "\n",
    "### Here is the brief!\n",
    "\n",
    "You need to estimate the total flow of oil, gas, and water through a choke valve. The total flow rate is labeled `QTOT`. You should use all measurements that may explain the total flow. Awesome Corp has already prepared these for you in a dataset (no further preprocessing is required). The measurements (features) are labeled as follows:\n",
    "- `CHK`: choke opening - a number in [0, 1], 1 meaning fully open and 0 meaning closed\n",
    "- `PWH`: pressure upstream the choke (scaled)\n",
    "- `PDC`: pressure downstream the choke (scaled)\n",
    "- `TWH`: temperature upstream the choke (scaled)\n",
    "- `FGAS`: fraction of gas to total flow - a number in [0,1]\n",
    "- `FOIL`: fraction of oil to total flow - a number in [0,1]\n",
    "\n",
    "The location of the sensors are shown in the figure below.\n",
    "\n",
    "<img src=\"well_sensors.png\">\n",
    "\n",
    "### Wait! There is one issue. The customer does not have a model for the total flow rate...\n",
    "\n",
    "A simple choke model for water flow is:\n",
    "$$QTOT = C_v(CHK) \\sqrt{\\frac{2(PWH - PDC)}{\\rho}}$$\n",
    "where $C_v(CHK)$ gives the cross-sectional area as a function of choke opening `CHK`.\n",
    "\n",
    "Unfortunately, there are complications that prevent us from using this model:\n",
    "\n",
    "1. We do not know what the correct equations are for multi-phase flow. For example, we expect gas expansions to be a factor. This factor is likely dependent on the temperature `TWH` and the amount of gas `FGAS`. Viscosity is probably a factor too, and that would depend on `FOIL`.\n",
    "2. We do not know the form of the choke $C_v$-curve.\n",
    "\n",
    "[Head scratch] Perhaps we can use a deep learning algorithm to learn a good representation of the data? Let us try to use all the available measurements to model `QTOT` using a neural network:\n",
    "$$QTOT = f_{\\theta}(CHK, PWH, PDC, TWH, FGAS, FOIL)$$\n",
    "\n",
    "Let's get to work!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/well_data.csv', index_col=0)\n",
    "print(df)\n",
    "# print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Plot the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 2, figsize=(16, 9))\n",
    "\n",
    "# Choke valve opening\n",
    "ax[0, 0].plot(df['CHK'], label='CHK')\n",
    "ax[0, 0].legend()\n",
    "\n",
    "# Total flow through choke valve\n",
    "ax[0, 1].plot(df['TWH'], label='TWH')\n",
    "ax[0, 1].legend()\n",
    "\n",
    "# Diff pressure over choke valve\n",
    "ax[1, 0].plot(df['PWH'] - df['PDC'], label='PWH - PDC')\n",
    "ax[1, 0].legend()\n",
    "\n",
    "# Fractions\n",
    "ax[1, 1].plot(df['FOIL'], label='FOIL')\n",
    "ax[1, 1].plot(df['FGAS'], '--r', label='FGAS')\n",
    "ax[1, 1].legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Split the data into a train, validation and test set\n",
    "\n",
    "Our test set consists of the examples indexed by [2000, 2499]. Our task is to estimate `QTOT` for this period.\n",
    "\n",
    "The rest of the data is split into a train (90%) and validation set (10%). We draw the validation data randomly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Test set (this is the period for which we must estimate QTOT)\n",
    "test_set = df.iloc[2000:2500]\n",
    "\n",
    "# Make a copy of the dataset and remove the test data\n",
    "train_val_set = df.copy().drop(test_set.index)\n",
    "\n",
    "# Sample validation data without replacement (10%)\n",
    "val_set = train_val_set.sample(frac=0.1, replace=False, random_state=random_seed)\n",
    "\n",
    "# The remaining data is used for training (90%)\n",
    "train_set = train_val_set.copy().drop(val_set.index)\n",
    "\n",
    "# Check that the numbers add up\n",
    "n_points = len(train_set) + len(val_set) + len(test_set)\n",
    "print(f'{len(df)} = {len(train_set)} + {len(val_set)} + {len(test_set)} = {n_points}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Plot the train, validation and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 9))\n",
    "plt.scatter(train_set.index, train_set['QTOT'], color='black', label='Train')\n",
    "plt.scatter(val_set.index, val_set['QTOT'], color='green', label='Val')\n",
    "plt.scatter(test_set.index, test_set['QTOT'], color='red', label='Test')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Neural network\n",
    "\n",
    "Here we specify how to construct our neural network $f_{\\theta}$. \n",
    "\n",
    "We use ReLU activation for the hidden layers:\n",
    "$$h^{(i)} = ReLU(W^{(i)} h^{(i-1)} + b^{(i)})$$\n",
    "\n",
    "The output layer is a simple linear layer since we will solve a regression problem.\n",
    "\n",
    "We use He initialization for the weights. The biases are initialized to zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    PyTorch offers several ways to construct neural networks.\n",
    "    Here we choose to implement the network as a Module class.\n",
    "    This gives us full control over the construction and clarifies our intentions.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, layers):\n",
    "        \"\"\"\n",
    "        Constructor of neural network\n",
    "        :param layers: list of layer widths. Note that len(layers) = network depth + 1 since we incl. the input layer.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "        assert len(layers) >= 2, \"At least two layers are required (incl. input and output layer)\"\n",
    "        self.layers = layers\n",
    "\n",
    "        # Fully connected linear layers\n",
    "        linear_layers = []\n",
    "\n",
    "        for i in range(len(self.layers) - 1):\n",
    "            n_in = self.layers[i]\n",
    "            n_out = self.layers[i+1]\n",
    "            layer = torch.nn.Linear(n_in, n_out)\n",
    "\n",
    "            # Initialize weights and biases\n",
    "            a = 1 if i == 0 else 2\n",
    "            layer.weight.data = torch.randn((n_out, n_in)) * sqrt(a / n_in)\n",
    "            layer.bias.data = torch.zeros(n_out)\n",
    "            \n",
    "            # Add to list\n",
    "            linear_layers.append(layer)\n",
    "        \n",
    "        # Modules/layers must be registered to enable saving of model\n",
    "        self.linear_layers = torch.nn.ModuleList(linear_layers)  \n",
    "\n",
    "        # Non-linearity (e.g. ReLU, ELU, or SELU)\n",
    "        self.act = torch.nn.ReLU(inplace=False)\n",
    "\n",
    "    def forward(self, input):\n",
    "        \"\"\"\n",
    "        Forward pass to evaluate network for input values\n",
    "        :param input: tensor assumed to be of size (batch_size, n_inputs)\n",
    "        :return: output tensor\n",
    "        \"\"\"\n",
    "        x = input\n",
    "        for l in self.linear_layers[:-1]:\n",
    "            x = l(x)\n",
    "            x = self.act(x)\n",
    "\n",
    "        output_layer = self.linear_layers[-1]\n",
    "        return output_layer(x)\n",
    "\n",
    "    def get_num_parameters(self):\n",
    "        return sum(p.numel() for p in self.parameters())\n",
    "\n",
    "    def save(self, path: str):\n",
    "        \"\"\"\n",
    "        Save model state\n",
    "        :param path: Path to save model state\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        torch.save({\n",
    "            'model_state_dict': self.state_dict(),\n",
    "        }, path)\n",
    "\n",
    "    def load(self, path: str):\n",
    "        \"\"\"\n",
    "        Load model state from file\n",
    "        :param path: Path to saved model state\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        checkpoint = torch.load(path, map_location=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "        self.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Training loop\n",
    "\n",
    "Below we implement the training procedure for the neural network. \n",
    "\n",
    "We loop over batches in the dataset (one pass through the dataset is called an _epoch_).\n",
    "\n",
    "For each batch B, we do a forward pass to compute the cost function:\n",
    "$$J(\\theta) = \\frac{1}{|B|} \\sum_{i \\in B} (y_i - f_{\\theta}(x_i))^2 + \\lambda \\lVert \\theta \\rVert_2^2$$\n",
    "\n",
    "We then do a backward pass to compute the gradient:\n",
    "$$\\frac{\\partial J}{\\partial \\theta}$$\n",
    "\n",
    "Finally, we update the parameters:\n",
    "$$\\theta \\leftarrow \\theta - \\alpha \\frac{\\partial J}{\\partial \\theta}$$\n",
    "\n",
    "Note that we use Adam so the update rule is actually a bit different than the one above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "        net: torch.nn.Module,\n",
    "        train_loader: DataLoader,\n",
    "        val_loader: DataLoader,\n",
    "        n_epochs: int,\n",
    "        lr: float,\n",
    "        l2_reg: float,\n",
    ") -> torch.nn.Module:\n",
    "    \"\"\"\n",
    "    Train model using mini-batch SGD\n",
    "    After each epoch, we evaluate the model on validation data\n",
    "\n",
    "    :param net: initialized neural network\n",
    "    :param train_loader: DataLoader containing training set\n",
    "    :param n_epochs: number of epochs to train\n",
    "    :param lr: learning rate (default: 0.001)\n",
    "    :param l2_reg: L2 regularization factor (default: 0)\n",
    "    :return: torch.nn.Module: trained model.\n",
    "    \"\"\"\n",
    "\n",
    "    # Define loss and optimizer\n",
    "    criterion = torch.nn.MSELoss(reduction='mean')\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "\n",
    "    # Train Network\n",
    "    for epoch in range(n_epochs):\n",
    "        for inputs, labels in train_loader:\n",
    "            # Zero the parameter gradients (from last iteration)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward propagation\n",
    "            outputs = net(inputs)\n",
    "            \n",
    "            # Compute cost function\n",
    "            batch_mse = criterion(outputs, labels)\n",
    "            \n",
    "            reg_loss = 0\n",
    "            for param in net.parameters():\n",
    "                reg_loss += param.pow(2).sum()\n",
    "\n",
    "            cost = batch_mse + l2_reg * reg_loss\n",
    "\n",
    "            # Backward propagation to compute gradient\n",
    "            cost.backward()\n",
    "            \n",
    "            # Update parameters using gradient\n",
    "            optimizer.step()\n",
    "        \n",
    "        # Evaluate model on validation data\n",
    "        mse_val = 0\n",
    "        for inputs, labels in val_loader:\n",
    "            mse_val += torch.sum(torch.pow(labels - net(inputs), 2)).item()\n",
    "        mse_val /= len(val_loader.dataset)\n",
    "        print(f'Epoch: {epoch + 1}: Val MSE: {mse_val}')\n",
    "        \n",
    "    return net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data for training\n",
    "\n",
    "We use the PyTorch DataLoader to simplify the partitioning of the training data into batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the target and features\n",
    "INPUT_COLS = ['CHK', 'PWH', 'PDC', 'TWH', 'FGAS', 'FOIL']\n",
    "OUTPUT_COLS = ['QTOT']\n",
    "\n",
    "# Get input and output tensors and convert them to torch tensors\n",
    "x_train = torch.from_numpy(train_set[INPUT_COLS].values).to(torch.float)\n",
    "y_train = torch.from_numpy(train_set[OUTPUT_COLS].values).to(torch.float)\n",
    "\n",
    "x_val = torch.from_numpy(val_set[INPUT_COLS].values).to(torch.float)\n",
    "y_val = torch.from_numpy(val_set[OUTPUT_COLS].values).to(torch.float)\n",
    "\n",
    "# Create dataset loaders\n",
    "# Here we specify the batch size and if the data should be shuffled\n",
    "train_dataset = torch.utils.data.TensorDataset(x_train, y_train)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=10, shuffle=True)\n",
    "\n",
    "val_dataset = torch.utils.data.TensorDataset(x_val, y_val)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=len(val_set), shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct and initialize the model\n",
    "\n",
    "The time to construct an actual neural network has finally come! \n",
    "\n",
    "Now, what should the network size be? How much data do we have? How nonlinear is the underlying function we are trying to model? Two to hidden layers with 50 units may be sufficient? Let's try that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "layers = [len(INPUT_COLS), 50, 50, len(OUTPUT_COLS)]\n",
    "net = Net(layers)\n",
    "\n",
    "print(f'Layers: {layers}')\n",
    "print(f'Number of model parameters: {net.get_num_parameters()}')\n",
    "# print(6*50 + 50 + 50*50 + 50 + 50 * 1 + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model\n",
    "\n",
    "Almost there. We only need to set some important hyper-parameters before we start the training. The number of epochs to train, the learning rate, and the L2 regularization factor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 100\n",
    "lr = 0.001\n",
    "l2_reg = 0.001  # 10\n",
    "net = train(net, train_loader, val_loader, n_epochs, lr, l2_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Evaluate the model on validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Predict on validation data\n",
    "pred_val = net(x_val)\n",
    "\n",
    "# Compute MSE, MAE and MAPE on validation data\n",
    "print('Error on validation data')\n",
    "\n",
    "mse_val = torch.mean(torch.pow(pred_val - y_val, 2))\n",
    "print(f'MSE: {mse_val.item()}')\n",
    "\n",
    "mae_val = torch.mean(torch.abs(pred_val - y_val))\n",
    "print(f'MAE: {mae_val.item()}')\n",
    "\n",
    "mape_val = 100*torch.mean(torch.abs(torch.div(pred_val - y_val, y_val)))\n",
    "print(f'MAPE: {mape_val.item()} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Are you happy with the result? \n",
    "\n",
    "Remember that the validation error is just an estimate of the test error (the error on new examples). The test error may be higher or lower. We may proceed if we believe that we have a good validation set and the validation error is sufficiently low.\n",
    "\n",
    "If we wish to proceed, a final step before we produce our estimates would be to re-train the model on both the train and validation data. We will skip this step for now.\n",
    "\n",
    "Let's see how well we did!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Evaluate the model on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Get input and output as torch tensors\n",
    "x_test = torch.from_numpy(test_set[INPUT_COLS].values).to(torch.float)\n",
    "y_test = torch.from_numpy(test_set[OUTPUT_COLS].values).to(torch.float)\n",
    "\n",
    "# Make prediction\n",
    "pred_test = net(x_test)\n",
    "\n",
    "# Compute MSE, MAE and MAPE on test data\n",
    "print('Error on test data')\n",
    "\n",
    "mse_test = torch.mean(torch.pow(pred_test - y_test, 2))\n",
    "print(f'MSE: {mse_test.item()}')\n",
    "\n",
    "mae_test = torch.mean(torch.abs(pred_test - y_test))\n",
    "print(f'MAE: {mae_test.item()}')\n",
    "\n",
    "mape_test = 100*torch.mean(torch.abs(torch.div(pred_test - y_test, y_test)))\n",
    "print(f'MAPE: {mape_test.item()} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Visual evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 9))\n",
    "plt.plot(y_test.numpy(), label='Missing QTOT')\n",
    "plt.plot(pred_test.detach().numpy(), label='Estimated QTOT')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# That's pretty good! \n",
    "\n",
    "But this is only the beginning. We have only set up the framework. Now you can be creative and experiment with different architectures, regularization techniques and hyper-parameters. I challenge you not to keep staring at those training curves as you wait for the result of a cool new idea - I am still hypnotized by them :-)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
