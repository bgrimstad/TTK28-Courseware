{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch\n",
    "\n",
    "In this brief tutorial we will get to know the basic functionality of PyTorch.\n",
    "\n",
    "PyTorch a Python-based scientific computing package targeted at two sets of audiences:\n",
    "- A replacement for NumPy to use the power of GPUs\n",
    "- A deep learning research platform that provides maximum flexibility and speed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constructing a scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty scalar (uninitialized)\n",
    "x = torch.empty(1)\n",
    "print(x)\n",
    "\n",
    "# From data\n",
    "x = torch.tensor([1])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data types\n",
    "\n",
    "PyTorch supports data types for integer, floating-point, complex, and boolean numbers. It is important to be aware of which data types we use since they may have a large impact on computational speed. PyTorch defaults to the single-precision 32-bit 'float32' for floating-point numbers since it provides sufficient precision for most ML tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data types\n",
    "x = torch.tensor([1])  # Integer\n",
    "print(x.type())\n",
    "\n",
    "x = torch.tensor([1.1])  # Float\n",
    "print(x.type())\n",
    "\n",
    "x = torch.tensor([1], dtype=torch.float)  # Specify data type\n",
    "print(x.type())\n",
    "\n",
    "# Above we printed the type of the data in x. What is the type of x?\n",
    "# print(type(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constructing a vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similar to constructing a scalar\n",
    "x = torch.tensor([1, 2, 3, 4])\n",
    "print(x)\n",
    "\n",
    "# There are some convenience methods like:\n",
    "print(torch.ones([4]))\n",
    "print(torch.zeros([4]))\n",
    "print(torch.rand([4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constructing a matrix or tensor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct a matrix of ones with shape (4, 3)\n",
    "print('A matrix')\n",
    "print(torch.ones([4, 3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constructing a tensor\n",
    "\n",
    "A tensor is an object that generalizes the concepts of scalars, vectors, and matrices to higher dimensions.\n",
    "- 0-order tensor = scalar\n",
    "- 1-order tensor = vector\n",
    "- 2-order tensor = matrix\n",
    "- 3-order tensor ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct a 3-order tensor\n",
    "print('A tensor')\n",
    "print(torch.ones([2, 4, 3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking the dimension and size of a tensor\n",
    "\n",
    "The dimension of a tensor is equal to the number of indices required to identify each component uniquely. The order of a tensor is equal to its dimension.\n",
    "\n",
    "Technical note: The dimension of the space of all similar-sized tensors is equal the number of tensor components. For example, the space of all 2x2 matrices is 4, but a 2x2 matrix is a 2-dimensional (or 2-order) tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.ones([2, 4, 3])\n",
    "print('Dim:', x.dim())\n",
    "print('Shape:', x.size())  # Number of elements along each dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A tensor, high-dimensional or not, is just a list of numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1d = [1, 2, 3, 4, 5, 6, 7, 8]\n",
    "\n",
    "a = torch.tensor(data_1d)\n",
    "\n",
    "print('Data as a vector')\n",
    "print(a)\n",
    "print(a.size())\n",
    "\n",
    "print()\n",
    "print('The same data as a matrix')\n",
    "b = a.reshape([2, 4])\n",
    "print(b)\n",
    "print(b.size())\n",
    "\n",
    "print()\n",
    "print('Data as a 3-D tensor')\n",
    "c = a.reshape([2, 2, 2])\n",
    "print(c)\n",
    "print(c.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# It is easy to convert a PyTorch tensor to a numpy array, and back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([1, 2, 3, -4])\n",
    "x_np = x.numpy()\n",
    "\n",
    "print('To a numpy array')\n",
    "print(x_np)\n",
    "\n",
    "print()\n",
    "print('Back to a PyTorch tensor')\n",
    "x_torch = torch.from_numpy(x_np)\n",
    "print(x_torch)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# PyTorch has many operators that work on tensors"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.abs(a))\n",
    "print(torch.pow(b, 2))\n",
    "print(torch.relu(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's do some calculation\n",
    "\n",
    "Let's try to do some matrix multiplications!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([1, 1, 1])\n",
    "b = torch.tensor([1, 2, 3, 4, 5, 6, 7, 8, 9]).reshape((3, 3))\n",
    "\n",
    "print('A matrix multiplication')\n",
    "print(torch.matmul(b, a))\n",
    "\n",
    "print()\n",
    "print('Element-wise multiplication - what happened here?')\n",
    "print(torch.mul(b, a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Broadcasting\n",
    "\n",
    "Like Numpy, PyTorch uses a concept called broadcasting, which can simplify our equations.\n",
    "But we need to be careful, it may also fool us!\n",
    "\n",
    "Operations on two tensors can be broadcast if\n",
    "1. Each tensor has at least one dimension.\n",
    "2. When iterating over the dimension sizes, starting at the trailing dimension, the dimension sizes must either be equal, one of them is 1, or one of them does not exist.\n",
    "\n",
    "You can read more about broadcasting in the [PyTorch documentation](https://pytorch.org/docs/stable/notes/broadcasting.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([1, 0, 0])\n",
    "b = torch.tensor([1, 2, 3, 4, 5, 6]).reshape((2, 3))\n",
    "c = b + a\n",
    "\n",
    "print('a vector')\n",
    "print(a)\n",
    "print(a.size())\n",
    "\n",
    "print()\n",
    "print('b matrix')\n",
    "print(b)\n",
    "print(b.size())\n",
    "\n",
    "print()\n",
    "print('c')\n",
    "print(c)\n",
    "print(c.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now, how do we compute gradients?\n",
    "\n",
    "We consider the function/graph:\n",
    "$$y = \\sum_{i=1}^2 x_i^2$$\n",
    "\n",
    "And wish to compute \n",
    "$$\\frac{\\partial y}{\\partial x}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(data=[0., 2.], requires_grad=True)\n",
    "y = torch.sum(torch.pow(x, 2))\n",
    "\n",
    "print('x:', x)\n",
    "print('y:', y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run backwards propagation to compute the gradients in the graph\n",
    "y.backward()\n",
    "\n",
    "# Print the gradient\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Computing for a neural networks follows the same principles"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
