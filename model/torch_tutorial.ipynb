{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch\n",
    "\n",
    "In this brief tutorial we will get to know the basic functionality of PyTorch.\n",
    "\n",
    "PyTorch a Python-based scientific computing package targeted at two sets of audiences:\n",
    "- A replacement for NumPy to use the power of GPUs\n",
    "- A deep learning research platform that provides maximum flexibility and speed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constructing a scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty scalar (uninitialized)\n",
    "x = torch.empty(1)\n",
    "print(x)\n",
    "\n",
    "# From data\n",
    "x = torch.tensor([1])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constructing a vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similar to constructing a scalar\n",
    "x = torch.tensor([1, 2, 3, 4])\n",
    "print(x)\n",
    "\n",
    "# There are some convenience methods like:\n",
    "print(torch.ones([4]))\n",
    "print(torch.zeros([4]))\n",
    "print(torch.rand([4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constructing a matrix or tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct a matrix of ones with shape (4, 3)\n",
    "print('A matrix')\n",
    "print(torch.ones([4, 3]))\n",
    "\n",
    "# In general, a tensor is a higher-dimensional object\n",
    "print()\n",
    "print('A tensor')\n",
    "print(torch.ones([2, 4, 3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking the dimension and shape of a tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.ones([2, 4, 3])\n",
    "print('Dim:', x.dim())\n",
    "print('Shape:', x.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A tensor, high-dimensional or not, is just a list of numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1d = [1, 2, 3, 4, 5, 6, 7, 8]\n",
    "\n",
    "a = torch.tensor(data_1d)\n",
    "\n",
    "print('Data as a vector')\n",
    "print(a)\n",
    "print(a.size())\n",
    "\n",
    "print()\n",
    "print('The same data as a matrix')\n",
    "b = a.reshape([2, 4])\n",
    "print(b)\n",
    "print(b.size())\n",
    "\n",
    "print()\n",
    "print('Data as a 3-D tensor')\n",
    "c = a.reshape([2, 2, 2])\n",
    "print(c)\n",
    "print(c.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# It is easy to convert a PyTorch tensor to a numpy array, and back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([1, 2, 3, -4])\n",
    "x_np = x.numpy()\n",
    "\n",
    "print('To a numpy array')\n",
    "print(x_np)\n",
    "\n",
    "print()\n",
    "print('Back to a PyTorch tensor')\n",
    "x_torch = torch.from_numpy(x_np)\n",
    "print(x_torch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# PyTorch has many operators that work on tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.abs(a))\n",
    "print(torch.pow(b, 2))\n",
    "print(torch.relu(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's do some calculation\n",
    "\n",
    "PyTorch uses a concept called broadcasting, which can simplify our equations.\n",
    "But we need to be careful, it may also fool us!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([1, 1, 1])\n",
    "b = torch.tensor([1, 2, 3, 4, 5, 6, 7, 8, 9]).reshape((3, 3))\n",
    "\n",
    "print('A matrix multiplication')\n",
    "print(torch.matmul(b, a))\n",
    "\n",
    "print()\n",
    "print('Element-wise multiplication (what happened here?)')\n",
    "print(torch.mul(b, a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now, how do we compute gradients?\n",
    "\n",
    "We consider the function/graph:\n",
    "$$y = \\sum_{i=1}^2 x_i^2$$\n",
    "\n",
    "And wish to compute \n",
    "$$\\frac{\\partial y}{\\partial x}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(data=[0., 2.], requires_grad=True)\n",
    "y = torch.sum(torch.pow(x, 2))\n",
    "\n",
    "print('x:', x)\n",
    "print('y:', y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run backwards propagation to compute the gradients in the graph\n",
    "y.backward()\n",
    "\n",
    "# Print the gradient\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Computing for a neural networks follows the same principles"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}